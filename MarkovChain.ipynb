{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# マルコフ連鎖\n",
    "人工無能の一番簡単な例.  \n",
    "大規模なツイート情報をくれた友人に感謝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "import MeCab\n",
    "\n",
    "from collections import Counter\n",
    "import json\n",
    "import os,re,random\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text\r\n",
      "寿司のフレンズと寿司会\r\n",
      "今回は嫁も一緒に( ◜ω‾)\r\n",
      "すしまみれ 新宿セントラルロード店 \r\n",
      "あまりにも勉強しなさ過ぎて開きっぱなしの問題集にホコリが乗ってるの草\r\n",
      "「休みだから家になっつんがいる嬉しい〜！」って騒いでたらカーペットにお弁当丸ごとひっくり返した......\r\n",
      " あるこさんおはようございます( ◜ω‾)\r\n",
      "だってやってらんないじゃん\r\n",
      "ストレスよりロマンスでしょ\r\n",
      " おはようございます( ◜ω‾)\r\n"
     ]
    }
   ],
   "source": [
    "!head TWEETandURL.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test:  今回は嫁も一緒に( ◜ω‾)<EOS>\n"
     ]
    }
   ],
   "source": [
    "filename=\"TWEETandURL.csv\" #任意のファイル名\n",
    "nrt_tweet = pd.read_csv(\"TWEETandURL.csv\",encoding='utf-8')[\"text\"][1:]\n",
    "words = []\n",
    "for _ in nrt_tweet:\n",
    "    words.append(_.strip()+\"<EOS>\")\n",
    "print(\"test: \",words[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1228\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "tmp=[]\n",
    "#mt = MeCab.Tagger(\"-Ochasen\")\n",
    "mt = MeCab.Tagger(' -d /usr/local/lib/mecab/dic/mecab-ipadic-neologd')\n",
    "mt.parse(\"\") #おまじない\n",
    "for i,tweet in enumerate(nrt_tweet[:100]):\n",
    "    #print(tweet,type(tweet))\n",
    "    node = mt.parseToNode(tweet.strip())\n",
    "    while node:\n",
    "        ch = node.surface\n",
    "        if ch == \"\":\n",
    "            node = node.next\n",
    "            continue\n",
    "        tmp.append(ch)\n",
    "        node = node.next\n",
    "print(len(tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#マルコフ連鎖の辞書\n",
    "def make_dic(words,dic):\n",
    "    tmp = [\"START\"]\n",
    "    for word in words:\n",
    "        #該当文字が来たら次の文字ヘスキップ\n",
    "        if word==\"\" or word==\"\\n\\t\" or word==\"\\n\":\n",
    "            continue\n",
    "        #3wordsになるまで文字を加える\n",
    "        tmp.append(word)\n",
    "        if len(tmp) < 3: \n",
    "            continue\n",
    "        #4単語 tmpに格納されているので一番古い一単語を除去\n",
    "        if len(tmp) > 3:\n",
    "            tmp = tmp[1:]\n",
    "        set_word3(dic,tmp)\n",
    "        if word == \"EOS\":\n",
    "            tmp = [\"START\"]\n",
    "            return dic\n",
    "            #continue\n",
    "    #print(dic)\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_word3(dic,s3):\n",
    "    w1,w2,w3 = s3\n",
    "    if not w1 in dic:\n",
    "        dic[w1] = {}\n",
    "    if not w2 in dic[w1]:\n",
    "        dic[w1][w2] = {}\n",
    "    if not w3 in dic[w1][w2]:\n",
    "        dic[w1][w2][w3] = 0\n",
    "    dic[w1][w2][w3] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D===============\n",
      "{}\n",
      "\n",
      "D================\n",
      "{'START': {'お腹': {'が': 1}}, 'お腹': {'が': {'今': 1}}, 'が': {'今': {'とても': 1}}, '今': {'とても': {'空いた': 1}}, 'とても': {'空いた': {'助けてくれ': 1}}, '空いた': {'助けてくれ': {'EOS': 1}}}\n",
      "\n",
      "D================\n",
      "{'START': {'お腹': {'が': 1}, '今': {'ハンバーガー': 1}}, 'お腹': {'が': {'今': 1}}, 'が': {'今': {'とても': 1, '食べたい': 1}}, '今': {'とても': {'空いた': 1}, 'ハンバーガー': {'が': 1}, '食べたい': {'EOS': 1}}, 'とても': {'空いた': {'助けてくれ': 1}}, '空いた': {'助けてくれ': {'EOS': 1}}, 'ハンバーガー': {'が': {'今': 1}}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#挙動テスト\n",
    "test_dic={}\n",
    "print(\"D===============\\n{}\\n\".format(test_dic))\n",
    "test_dic = make_dic([\"お腹\",\"が\",\"今\",\"とても\",\"空いた\",\"助けてくれ\",\"EOS\"],test_dic)\n",
    "print(\"D================\\n{}\\n\".format(test_dic))\n",
    "test_dic = make_dic([\"今\",\"ハンバーガー\",\"が\",\"今\",\"食べたい\",\"EOS\"],test_dic)\n",
    "print(\"D================\\n{}\\n\".format(test_dic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ツイートの自動生成\n",
    "def make_tweet(dic,top_word=\"START\"):\n",
    "    ret = []\n",
    "    if not top_word in dic:\n",
    "        return \"no dic\"\n",
    "    #top = dic[\"START\"]\n",
    "    top = dic[top_word]\n",
    "    w1 = word_choice(top)\n",
    "    if top_word != \"START\":\n",
    "        w1 = top_word\n",
    "    w2 = word_choice(top[w1])\n",
    "    ret.append(w1)\n",
    "    ret.append(w2)\n",
    "    flag = True\n",
    "    if w1 == \"EOS\" or w2 == \"EOS\":\n",
    "        flag = False\n",
    "    while flag:\n",
    "        #print(dic[w1][w2])\n",
    "        try:\n",
    "            #print(\"CHECK1: \",w1,w2)\n",
    "            #print(\"CHECK2: \",dic[w1][w2])\n",
    "            w3 = word_choice(dic[w1][w2])\n",
    "            if w3 == \"EOS\":\n",
    "                break\n",
    "            ret.append(w3)\n",
    "            w1,w2 = w2,w3\n",
    "        except {KeyError,TypeError} as e:\n",
    "            print(e)\n",
    "            #print(dic[w1][w2])\n",
    "    return \"\".join(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_choice(sel):\n",
    "    keys = sel.keys()\n",
    "    L = random.choice(list(keys))\n",
    "    #print(keys,L)\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(tweets,markov_file=None):\n",
    "    '''\n",
    "    tweets : 全ツイート\n",
    "    markov_file : 辞書ですね\n",
    "    '''\n",
    "    #dict_file = markov_file\n",
    "    #if os.path.exists(dict_file):\n",
    "    #    return json.load(open(dict_file,\"r\"))\n",
    "    tagger = MeCab.Tagger('-Owakati')\n",
    "    #tagger = MeCab.Tagger(' -d /usr/local/lib/mecab/dic/mecab-ipadic-neologd')\n",
    "    dic={}\n",
    "    for i,tweet in enumerate(tweets):\n",
    "        #print(i)\n",
    "        nodes = tagger.parseToNode(tweet)\n",
    "        #辞書を作成する\n",
    "        #dic = make_dic(nodes)\n",
    "        words=[\"\"] #分かち書きした単語をリストに加える\n",
    "        while nodes:\n",
    "            if nodes.surface==\"\":\n",
    "                nodes = nodes.next\n",
    "            else:\n",
    "                words.append(nodes.surface)\n",
    "                nodes = nodes.next\n",
    "        words.append(\"EOS\")\n",
    "        dic = make_dic(words,dic) #マルコフ連鎖の辞書へ\n",
    "        #json.dump(dic,open(dict_file,\"w\"))\n",
    "    return dic\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "書き込み終了\n"
     ]
    }
   ],
   "source": [
    "#辞書格納 and ファイルに書き込むとき用\n",
    "dic = main(nrt_tweet)\n",
    "json.dump(dic,open(\"markov_dict.json\",\"w\"))\n",
    "print(\"書き込み終了\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,灰になっちゃったりしない系ツイートかと詰め込んだようだ！😄✴✨」\n",
      "2,買おうとおもいまふぁみふぁみまー♪しましたは現実世界は言葉が出ない妥当性を示唆\n",
      "3,デレて\n",
      "4,ケトル以外高過ぎて俺とLINEする人，バンバン留年した失敗しました😌🙌🏻\n",
      "5,中高体操部ってオタクおすすめの牛角新宿歌舞伎町で黒人のゴツイにーがー＼＼\\└('ω')┘//／／!!\n",
      "6,....oh........nothankyou！なんか髪の毛もじゃもじゃでｵﾃﾝｺみたいなモブいた据え置きのパソコンが勝手に載るのな(･へ･)\n",
      "7,話し相手が居たのでホイホイ付いていどねぇ......(ﾁﾗﾁﾗﾁﾗﾁﾗﾁﾗ)\n",
      "8,ぬるぬる動くあきやまさん\n",
      "9,ダックイン\n",
      "10,幅広いジャンルで活用できるって、切りどころそこじゃない本は研究室面接対策\n"
     ]
    }
   ],
   "source": [
    "#f=open(\"NRT_Markov_Result.csv\",\"w\")\n",
    "for i in range(10):\n",
    "    print(i+1,make_tweet(dic).replace(\"EOS\",\"\"),sep=\",\")\n",
    "#f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
