{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Armed-Bandit Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Library\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## agent(環境)\n",
    "今回の場合はスロットを用意する  \n",
    "報酬周りがよくわからない(´･ω･｀)  現在はベルヌーイ分布の結果を報酬としている.. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ベルヌーイ分布\n",
    "\n",
    "$$\n",
    "    f(k;p) = \\begin{cases}\n",
    "        p  & k=1\\\\\n",
    "        1-p & k=0\n",
    "    \\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 当たるor当たらない\n",
    "class BernoulliArm():\n",
    "    def __init__(self,p):\n",
    "        self.p = p\n",
    "    \n",
    "    def draw(self):\n",
    "        if random.random() > self.p:\n",
    "            return 0.0\n",
    "        else:\n",
    "            return 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ガウシアン分布\n",
    "\n",
    "$$ \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} exp(- \\frac{(x - \\mu)^2}{2\\sigma^2}) $$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 正規分布\n",
    "class NormalArm():\n",
    "    def __init__(self,mu,sigma):\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "    \n",
    "    def draw(self):\n",
    "        return random.gauss(self.mu,self.sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.438368849514714"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## sample(標準正規分布)\n",
    "arm_test = NormalArm(0,1)\n",
    "arm_test.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### greedy algorithm\n",
    "まだn回選んだことがない腕がある場合, その腕を選出  \n",
    "それ以外の場合, 全ての腕に対して, これまでの報酬の平均を計算する  \n",
    "  \n",
    "$$ u_i = \\frac{これまで腕iから得られた報酬の和}{これまで腕iをプレイした回数} $$  \n",
    "\n",
    "u_i が最大の腕を選ぶ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#リスト内の最大値または最小値のインデックスを返す関数\n",
    "def ind(x,option=\"max\"):\n",
    "    if option==\"min\":\n",
    "        m = min(x)\n",
    "    else:\n",
    "        m = max(x)\n",
    "    return x.index(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Greedy():\n",
    "    def __init__(self,counts,values):\n",
    "        self.counts = counts\n",
    "        self.values = values\n",
    "        \n",
    "    def initialize(self,n_arms):\n",
    "        self.counts = [0 for col in range(n_arms)]\n",
    "        self.values = [0.0 for col in range(n_arms)]\n",
    "    \n",
    "    def select_arm(self):\n",
    "        count_min = min(self.counts)\n",
    "        #n回に達していない場合は達していないマシンの中で一番回数の低いマシンを選出\n",
    "        if count_min < n:\n",
    "            return self.counts.index(count_min)\n",
    "        #全て達している場合には報酬の最大になるマシンを選出\n",
    "        else:\n",
    "            return ind(self.values)\n",
    "            \n",
    "    def update(self,choose_arm,reward):\n",
    "        self.counts[choose_arm] = self.counts[choose_arm] +1 \n",
    "        value = self.values[choose_arm] #選んだマシンの報酬\n",
    "        #new_value = (value + reward)/ self.counts[choose_arm]\n",
    "        new_value = ((n-1)/float(n))*value + (1/float(n))*reward\n",
    "        self.values[choose_arm] = new_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ε - greedy algorithm\n",
    "まだ選んだことがない腕がある場合、その腕から一つ選ぶ  \n",
    "確率εで、すべての腕からランダムに一つ選ぶ  \n",
    "確率１−εで、これまでの報酬の平均u_i が最大の腕を選ぶ  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "class epsilon_Greedy():\n",
    "    def __init__(self,epsilon,counts,values):\n",
    "        self.epsilon = epsilon\n",
    "        self.counts = counts\n",
    "        self.values = values\n",
    "        \n",
    "    def initialize(self,n_arms):\n",
    "        self.counts = [0 for col in range(n_arms)]\n",
    "        self.values = [0.0 for col in range(n_arms)]\n",
    "    \n",
    "    def select_arm(self):\n",
    "        if random.random() > self.epsilon:\n",
    "            return ind(self.values)\n",
    "        #全て達している場合には報酬の最大になるマシンを選出\n",
    "        else:\n",
    "            return random.randrange(len(self.values))\n",
    "            \n",
    "    def update(self,choose_arm,reward):\n",
    "        self.counts[choose_arm] = self.counts[choose_arm] +1 \n",
    "        value = self.values[choose_arm] #選んだマシンの既存報酬\n",
    "        #new_value = (value + reward)/ self.counts[choose_arm]\n",
    "        new_value = ((n-1)/float(n))*value + (1/float(n))*reward\n",
    "        self.values[choose_arm] = new_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### demo\n",
    "スロットマシンを3台, 各マシンを3回ずつ回す(初期設定)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6 180.0\n"
     ]
    }
   ],
   "source": [
    "armTest = BernoulliArm(0.6)\n",
    "res=0\n",
    "reaw=0\n",
    "for i in range(100):\n",
    "    tmpDraw=armTest.draw()\n",
    "    reaw+=tmpDraw*300\n",
    "    res+=tmpDraw\n",
    "print(res/100,reaw/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "内訳:[100, 100, 100, 9700] 価値[0.19863667250041142, 0.20264185047914524, 0.26472267933149707, 0.4861824209836211]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  1.,   1.,   1.,  97.])"
      ]
     },
     "execution_count": 549,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "armA = BernoulliArm(0.2)\n",
    "armB = BernoulliArm(0.3)\n",
    "armC = BernoulliArm(0.4)\n",
    "armD = BernoulliArm(0.5)\n",
    "#armC = BernoulliArm(0.2)\n",
    "arms = [armA,armB,armC,armD]\n",
    "n_arms = len(arms)\n",
    "\n",
    "\n",
    "n = 100 #最初に探索する情報を取得\n",
    "\n",
    "algo = Greedy([],[])\n",
    "algo.initialize(n_arms)\n",
    "\n",
    "'''\n",
    "oxdict={0:\"o\",1:\"x\"}\n",
    "print(\"施行,行動,結果\")\n",
    "for i in range(6):\n",
    "    choose_arm = algo.select_arm()\n",
    "    reward = arms[choose_arm].draw()\n",
    "    algo.update(choose_arm,reward)\n",
    "    print(\"{},{},{}\".format(i,choose_arm,oxdict[reward]))\n",
    "\n",
    "print(\"内訳:{} 価値{}\".format(algo.counts,algo.values))\n",
    "\n",
    "for j in range(10):\n",
    "    choose_arm = algo.select_arm()\n",
    "    reward = arms[choose_arm].draw()\n",
    "    algo.update(choose_arm,reward)\n",
    "    print(\"{},{},{}\".format(i+j+1,choose_arm,oxdict[reward]))\n",
    "    \n",
    "print(\"内訳:{} 価値{}\".format(algo.counts,algo.values))\n",
    "'''\n",
    "arm_A,arm_B,arm_C,arm_D = [],[],[],[]\n",
    "for i in range(10000):\n",
    "    choose_arm = algo.select_arm()\n",
    "    reward = arms[choose_arm].draw()\n",
    "    algo.update(choose_arm,reward)\n",
    "    \n",
    "print(\"内訳:{} 価値{}\".format(algo.counts,algo.values))\n",
    "np.array(algo.counts)/10000 * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "内訳:[1896, 236, 3768, 4100] 価値[0.19904694558896596, 0.2869443250735782, 0.3973231087963187, 0.5167811277932451]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 18.96,   2.36,  37.68,  41.  ])"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "armA = BernoulliArm(0.2)\n",
    "armB = BernoulliArm(0.3)\n",
    "armC = BernoulliArm(0.4)\n",
    "armD = BernoulliArm(0.5)\n",
    "#armC = BernoulliArm(0.2)\n",
    "arms = [armA,armB,armC,armD]\n",
    "n_arms = len(arms)\n",
    "\n",
    "\n",
    "n = 100 #最初に探索する情報を取得\n",
    "\n",
    "algo = epsilon_Greedy(0.1,[],[])\n",
    "algo.initialize(n_arms)\n",
    "for i in range(10000):\n",
    "    choose_arm = algo.select_arm()\n",
    "    reward = arms[choose_arm].draw()\n",
    "    algo.update(choose_arm,reward)\n",
    "    \n",
    "print(\"内訳:{} 価値{}\".format(algo.counts,algo.values))\n",
    "np.array(algo.counts)/10000 * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upper Confidence Bound(UCB) Algorithm  \n",
    "得られた評価値の信頼性を自動的に高めようとする. あまりよくわかっていない腕は積極的に使用する.\n",
    "\n",
    "#### ~ Algotirhm\n",
    "R: 振戻額の最大値と最小値の差  \n",
    "まだ選出したことがない腕があれば, そのうちの一つを選ぶ  \n",
    "各々の腕iから得られる報酬の期待値を計算する  \n",
    "\n",
    "$$ u_i = \\frac{これまで腕iから得られた報酬の和}{これまで腕iを選んだ回数} $$ \n",
    "\n",
    "各々の腕iから得られる報酬の信頼区間の半幅を計算する  \n",
    "\n",
    "$$ U_i = R \\sqrt{\\frac{2 ln(これまでの総プレイ回数)}{これまで腕iをプレイした回数}} $$\n",
    "\n",
    "そして\n",
    "$$ u_i + U_i  が最大の腕 i を選出する $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 538,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(algo.counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class UCB():\n",
    "    def __init__(self,counts,values):\n",
    "        self.counts = counts\n",
    "        self.values = values\n",
    "    \n",
    "    def initialize(self,n_arms):\n",
    "        self.counts = [0 for col in range(n_arms)]\n",
    "        self.values = [0.0 for col in range(n_arms)]\n",
    "    \n",
    "    def select_arm(self):\n",
    "        n_arms = len(self.counts)\n",
    "        for arm in range(n_arms):\n",
    "            if self.counts[arm] == 0:\n",
    "                return arm\n",
    "        ucb_values = [0.0 for arm in range(n_arms)]\n",
    "        total_counts = sum(self.counts)\n",
    "        \n",
    "        for arm in range(n_arms):\n",
    "            bonus = math.sqrt((2*math.log(total_counts))/ float(self.counts[arm]))\n",
    "            ucb_values[arm] = self.values[arm] + bonus\n",
    "        \n",
    "        return ind(ucb_values)\n",
    "    \n",
    "    def update(self,chosen_arm,reward):\n",
    "        self.counts[chosen_arm] = self.counts[chosen_arm] +1\n",
    "        n = self.counts[chosen_arm]\n",
    "        \n",
    "        value = self.values[chosen_arm]\n",
    "        new_value = ((n-1)/float(n))*value + (1/float(n))*reward\n",
    "        self.values[chosen_arm] = new_value\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "内訳:[181, 316, 1248, 8255] 価値[0.22651933701657467, 0.30379746835443056, 0.42387820512820484, 0.498606904906118]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  1.81,   3.16,  12.48,  82.55])"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "armA = BernoulliArm(0.2)\n",
    "armB = BernoulliArm(0.3)\n",
    "armC = BernoulliArm(0.4)\n",
    "armD = BernoulliArm(0.5)\n",
    "#armC = BernoulliArm(0.2)\n",
    "arms = [armA,armB,armC,armD]\n",
    "n_arms = len(arms)\n",
    "\n",
    "\n",
    "n = 100 #最初に探索する情報を取得\n",
    "\n",
    "algo = UCB([],[])\n",
    "algo.initialize(n_arms)\n",
    "for i in range(10000):\n",
    "    choose_arm = algo.select_arm()\n",
    "    reward = arms[choose_arm].draw()\n",
    "    algo.update(choose_arm,reward)\n",
    "    \n",
    "print(\"内訳:{} 価値{}\".format(algo.counts,algo.values))\n",
    "np.array(algo.counts)/10000 * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
